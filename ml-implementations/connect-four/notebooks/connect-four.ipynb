{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./../../../games/connect-four/connect-four.py\n",
    "import numpy as np\n",
    "\n",
    "class ConnectFourSimulator:\n",
    "\t\"\"\"Creates a connect-4 board and simulates it, returning states and rewards for any taken action.\n",
    "\n",
    "\tThe creates board is a 6 x 7 (rows x cols) array. Empty fields are denoted by 0.\n",
    "\tTokens placed by player one are denoted by '1' and player two uses '-1'.\n",
    "\tEvery field is part of the state and has it's own index, simply counting from 0 to 41 along the rows\n",
    "\tlike so [\n",
    "\t\t[0, 1, 2, 3, 4, 5, 6],\n",
    "\t\t[7, 8, 9, 10, 11, 12, 13],\n",
    "\t\t...\n",
    "\t\t[35, 36, 37, 38, 39, 40, 41]\n",
    "\t]\n",
    "\t\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.width = 7\n",
    "\t\tself.height = 6\n",
    "\t\tself.board = np.zeros(shape=(self.height, self.width))\n",
    "\t\tself.PLAYER1 = 1\n",
    "\t\tself.PLAYER2 = -1\n",
    "\t\tself.DRAW = 0\n",
    "\t\tself.current_player = self.PLAYER1\n",
    "\t\tself.__game_over = False\n",
    "\n",
    "\tdef take_action(self, action):\n",
    "\t\t\"\"\"Executes the action and returns the next state and the received reward.\"\"\"\n",
    "\t\tactive_player = self.current_player\n",
    "\t\tinactive_player = self.__negated_player(active_player)\n",
    "\t\tif not self.__action_is_valid(action):\n",
    "\t\t\treturn self.__game_over, np.copy(self.board), active_player, -2, inactive_player, 0\n",
    "\n",
    "\t\tself.__play_move(action)\n",
    "\n",
    "\t\tself.__game_over = self.__game_is_over(action)\n",
    "\t\tif self.__game_over:\n",
    "\t\t\twinner = self.__winner(action)\n",
    "\t\t\tif winner == self.DRAW:\n",
    "\t\t\t\treturn self.__game_over, np.copy(self.board), active_player, 0, inactive_player, 0\n",
    "\t\t\telif winner == self.PLAYER1:\n",
    "\t\t\t\treturn self.__game_over, np.copy(self.board), active_player, 1000, inactive_player, -100\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.__game_over, np.copy(self.board), active_player, -100, inactive_player, 1000\n",
    "\n",
    "\t\treturn self.__game_over, np.copy(self.board), active_player, 0, inactive_player, 0\n",
    "\n",
    "\tdef print_board(self):\n",
    "\t\t#print(self.board)\n",
    "\t\tboard = self.board\n",
    "\t\tboard = np.where(board == 1, \"X\", board)\n",
    "\t\tboard = np.where(board == \"-1.0\", \"O\", board)\n",
    "\t\tprint(np.where(board == \"0.0\", \"-\", board))\n",
    "\n",
    "\tdef __play_move(self, action):\n",
    "\t\t\"\"\"Takes an action and executes it.\"\"\"\n",
    "\t\tx, y = self.__coordinates_from_action(action)\n",
    "\t\tself.board[y][x] = self.current_player\n",
    "\t\tself.current_player = self.__negated_player(self.current_player)\n",
    "\n",
    "\tdef __action_is_valid(self, action):\n",
    "\t\t\"\"\"Checks if the intended action is a valid one or if it breaks the rules of the game.\"\"\"\n",
    "\t\tif 41 > action < 0:\n",
    "\t\t\treturn False\n",
    "\t\tx, y = self.__coordinates_from_action(action)\n",
    "\t\tif x >= self.width or y >= self.height:\n",
    "\t\t\treturn False\n",
    "\n",
    "\t\theight_x = self.__column_height(x)\n",
    "\n",
    "\t\tif y != height_x:\n",
    "\t\t\treturn False\n",
    "\t\treturn True\n",
    "\n",
    "\tdef __column_height(self, x):\n",
    "\t\t\"\"\"Returns the height of a column which is equal to the amount of tokens placed.\"\"\"\n",
    "\t\tcolumn = self.board[:, x]\n",
    "\t\treturn np.count_nonzero(column)\n",
    "\n",
    "\tdef __game_is_over(self, last_action):\n",
    "\t\t\"\"\"Returns True if the game is over and False otherwise.\"\"\"\n",
    "\t\tif np.count_nonzero(self.board) >= 42:\n",
    "\t\t\treturn True\n",
    "\n",
    "\t\tlines = self.__extract_lines(last_action)\n",
    "\n",
    "\t\tfor line in lines:\n",
    "\t\t\tif self.__winner_in_line(line) != 0:\n",
    "\t\t\t\treturn True\n",
    "\n",
    "\t\treturn False\n",
    "\n",
    "\tdef __extract_lines(self, last_action):\n",
    "\t\t\"\"\"Extracts the horizontal, vertical and the diagonal lines going through the last action\"\"\"\n",
    "\t\tx, y = self.__coordinates_from_action(last_action)\n",
    "\n",
    "\t\trow = self.board[y]\n",
    "\t\tcolumn = self.board[:, x]\n",
    "\t\ttop_down_diagonal = self.board.diagonal(x - y)\n",
    "\n",
    "\t\tmirrored_x = self.width - 1 - x\n",
    "\t\tbot_up_diagonal = np.fliplr(self.board).diagonal(mirrored_x - y)\n",
    "\n",
    "\t\treturn row, column, top_down_diagonal, bot_up_diagonal\n",
    "\n",
    "\tdef __winner(self, last_action):\n",
    "\t\t\"\"\"Returns the winner's number or 0 if the game resulted in a draw (Requires the game to have ended).\"\"\"\n",
    "\t\tlines = self.__extract_lines(last_action)\n",
    "\n",
    "\t\tfor line in lines:\n",
    "\t\t\twinner = self.__winner_in_line(line)\n",
    "\t\t\tif winner != 0:\n",
    "\t\t\t\treturn winner\n",
    "\n",
    "\t\treturn 0\n",
    "\n",
    "\tdef __winner_in_line(self, line):\n",
    "\t\t\"\"\"Checks if a line contains a winner and returns his number if yes and 0 otherwise.\"\"\"\n",
    "\t\ttoken_sum = 0\n",
    "\t\tfor token in line:\n",
    "\t\t\ttoken_sum += token\n",
    "\t\t\tif token_sum == 4 * self.PLAYER1:\n",
    "\t\t\t\treturn self.PLAYER1\n",
    "\t\t\tif token_sum == 4 * self.PLAYER2:\n",
    "\t\t\t\treturn self.PLAYER2\n",
    "\t\t\tif token_sum < 0 < token or token_sum > 0 > token:\n",
    "\t\t\t\ttoken_sum = 0\n",
    "\t\treturn 0\n",
    "\n",
    "\tdef __coordinates_from_action(self, action):\n",
    "\t\t\"\"\"Translates an action into (x, y) / (column, row) coordinates.\"\"\"\n",
    "\t\tx = action % self.width\n",
    "\t\ty = action // self.width\n",
    "\t\treturn x, y\n",
    "\n",
    "\tdef __negated_player(self, player):\n",
    "\t\t\"\"\"Returns the player not passed to the function (Player1 if Player2 is passed and the other way around).\"\"\"\n",
    "\t\treturn self.PLAYER2 if self.current_player == self.PLAYER1 else self.PLAYER1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ConnectFourSimulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val = input()\n",
    "while val != \"q\":\n",
    "    game_over, board, _, _, _, _ = game.take_action(int(val))\n",
    "    print(game_over)\n",
    "    print(board)\n",
    "    print(\"------------------------------------\")\n",
    "    val = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(game.take_action(3))\n",
    "print(game.take_action(4))\n",
    "print(game.take_action(10))\n",
    "print(game.take_action(5))\n",
    "print(game.take_action(17))\n",
    "print(game.take_action(6))\n",
    "print(game.take_action(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 64)\n",
    "        #self.fc1.weight.data.fill_(0.0)\n",
    "        #self.fc1.bias.data.fill_(0.0)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        #self.fc2.weight.data.fill_(0.0)\n",
    "        #self.fc2.bias.data.fill_(0.0)\n",
    "        self.fc3 = nn.Linear(64, 42)\n",
    "        #self.fc3.weight.data.fill_(0.0)\n",
    "        #self.fc3.bias.data.fill_(0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class DeepQPytorchAgent:\n",
    "    def __init__(self, learning_rate=0.0001, discount=0.95, exploration_rate=1.0, iterations=10_000, trained_model=None):\n",
    "        self.q_table = np.zeros(shape=(42, 42))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount = discount\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_delta = exploration_rate / iterations\n",
    "        \n",
    "        self.input_count = 42\n",
    "        self.output_count = 42\n",
    "        \n",
    "        self.define_model(trained_model)\n",
    "    \n",
    "    def define_model(self, trained_model):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if trained_model:\n",
    "            self.model = trained_model.to(self.device)\n",
    "        else:\n",
    "            self.model = Model().to(self.device)\n",
    "        \n",
    "        #self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def get_Q(self, state):\n",
    "        x = torch.tensor(state.flatten(), device=self.device).float()\n",
    "        return self.model(x)\n",
    "    \n",
    "    def get_Q_batch(self, states):\n",
    "        #x = torch.tensor(state.flatten(), device=self.device).float()\n",
    "        return self.model(states)\n",
    "        \n",
    "    def next_action(self, state):\n",
    "        if random.random() < self.exploration_rate:\n",
    "            return self.random_action()\n",
    "        else:\n",
    "            return self.greedy_action(state)\n",
    "        \n",
    "    def random_action(self):\n",
    "        return random.randrange(0, 42) # Maybe change the probability distribution?\n",
    "    \n",
    "    def greedy_action(self, state):\n",
    "        #print(\"Greedy1:\", torch.max(self.get_Q(state), 0)[0])\n",
    "        #print(\"Greedy2:\", torch.max(self.get_Q(state), 0)[1])\n",
    "        return torch.max(self.get_Q(state), 0)[1]\n",
    "    \n",
    "    def update(self, old_state, new_state, action, reward):\n",
    "        self.train(old_state, new_state, action, reward)\n",
    "        # TODO: Maybe change algorithm?\n",
    "        if self.exploration_rate > 0:\n",
    "            self.exploration_rate = max(0.2, self.exploration_rate - self.exploration_delta)\n",
    "        \n",
    "    def update_batch(self, old_states, new_states, actions, rewards):\n",
    "        self.train_batch(old_states, new_states, actions, rewards)\n",
    "        \n",
    "        if self.exploration_rate > 0:\n",
    "            self.exploration_rate = max(0.05, self.exploration_rate - self.exploration_delta)\n",
    "\n",
    "    def train(self, old_state, new_state, action, reward):\n",
    "        #print(\"OldState:\", old_state)\n",
    "        #print(\"NewState:\", new_state)\n",
    "        #print(\"Reward:\", reward)\n",
    "        old_state_values = self.get_Q(old_state)\n",
    "        new_state_values = self.get_Q(new_state).detach()\n",
    "        #print(\"OldQ:\", old_state_values)\n",
    "        #print(\"NewQ:\", new_state_values)\n",
    "        \n",
    "        new_reward = reward + self.discount * torch.max(new_state_values)\n",
    "        #print(\"NewReward:\", new_reward)\n",
    "        updated_state_values = old_state_values.clone().detach() # Check if detach could cause problems\n",
    "        #print(\"BeforeUpdate:\", updated_state_values)\n",
    "        #print(\"Updating action:\", action)\n",
    "        updated_state_values[action] = new_reward\n",
    "        #print(\"OldAfterUpdate:\", old_state_values)\n",
    "        #print(\"UpdAfterUpdate:\", updated_state_values)\n",
    "        \n",
    "        # in your training loop:\n",
    "        self.optimizer.zero_grad()   # zero the gradient buffers\n",
    "        #loss = torch.autograd.Variable(F.smooth_l1_loss(old_state_values, updated_state_values), requires_grad=True)\n",
    "        loss = F.smooth_l1_loss(old_state_values, updated_state_values)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()    # Does the update\n",
    "        \n",
    "    def train_batch(self, old_states, new_states, actions, rewards):\n",
    "        old_state_values = self.get_Q_batch(old_states).gather(1, actions)\n",
    "        new_state_values = torch.zeros(len(new_states), device=self.device)\n",
    "        new_state_values = self.get_Q_batch(new_states).max(1)[0].detach()\n",
    "        \n",
    "        # Expected values\n",
    "        updated_state_values = rewards + (self.discount * next_state_values)\n",
    "        loss = F.smooth_l1_loss(old_state_values, updated_state_values.unsqueeze(1))\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # for param in policy_net.parameters():\n",
    "        #    param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class DeepQTensorflowAgent:\n",
    "    def __init__(self, learning_rate=0.1, discount=0.95, exploration_rate=1.0, iterations=10_000):\n",
    "        self.q_table = np.zeros(shape=(42, 42))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount = discount\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_delta = exploration_rate / iterations\n",
    "        \n",
    "        self.input_count = 42\n",
    "        self.output_count = 42\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.define_model()\n",
    "        self.session.run(self.initializer)\n",
    "    \n",
    "    def define_model(self):\n",
    "        self.model_input = tf.placeholder(dtype=tf.float32, shape=[ None, self.input_count ])\n",
    "        \n",
    "        fc1 = tf.layers.dense(self.model_input, 16, activation=tf.sigmoid, kernel_initializer=tf.constant_initializer(np.zeros((self.input_count, 5))))\n",
    "        fc2 = tf.layers.dense(fc1, 16, activation=tf.sigmoid, kernel_initializer=tf.constant_initializer(np.zeros((6, self.output_count))))\n",
    "        \n",
    "        self.model_output = tf.layers.dense(fc2, self.output_count)\n",
    "        \n",
    "        self.target_output = tf.placeholder(shape=[ None, self.output_count ], dtype=tf.float32)\n",
    "        loss = tf.losses.mean_squared_error(self.target_output, self.model_output)\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
    "        \n",
    "        self.initializer = tf.global_variables_initializer()\n",
    "    \n",
    "    def get_Q(self, state):\n",
    "        # Batching!! Dimensions!\n",
    "        return self.session.run(self.model_output, feed_dict={ self.model_input: [state.flatten()] })[0]\n",
    "        \n",
    "    def next_action(self, state):\n",
    "        if random.random() < self.exploration_rate:\n",
    "            return self.random_action()\n",
    "        else:\n",
    "            return self.greedy_action(state)\n",
    "        \n",
    "    def random_action(self):\n",
    "        return random.randrange(0, 42) # Maybe change the probability distribution?\n",
    "    \n",
    "    def greedy_action(self, state):\n",
    "        return np.argmax(self.get_Q(state))\n",
    "    \n",
    "    def update(self, old_state, new_state, action, reward):\n",
    "        self.train(old_state, new_state, action, reward)\n",
    "        # TODO: Maybe change algorithm?\n",
    "        if self.exploration_rate > 0:\n",
    "            self.exploration_rate = max(0.05, self.exploration_rate - self.exploration_delta)\n",
    "        \n",
    "    def train(self, old_state, new_state, action, reward):\n",
    "        old_state_values = self.get_Q(old_state)\n",
    "        new_state_values = self.get_Q(new_state)\n",
    "        \n",
    "        new_reward = reward + self.discount * np.amax(new_state_values)\n",
    "        old_state_values[action] = new_reward\n",
    "        \n",
    "        training_input = [old_state.flatten()]\n",
    "        target_output = [ old_state_values ]\n",
    "        training_data = { self.model_input: training_input, self.target_output: target_output }\n",
    "        \n",
    "        self.session.run(self.optimizer, feed_dict=training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('old_state', 'next_state', 'action', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(game, active, passive):\n",
    "    old_state = np.copy(game.board)\n",
    "    action = active.next_action(old_state)\n",
    "    \n",
    "    game_over, new_state, _, reward, _, _ = game.take_action(action)\n",
    "        \n",
    "    if game_over:\n",
    "        return True, old_state, new_state, action, reward\n",
    "            \n",
    "    # if the move was invalid, add data and repeat\n",
    "    if reward < 0:\n",
    "        return False, old_state, new_state, action, reward\n",
    "        \n",
    "    # Play another move until the move is a right one and add the data to the memory\n",
    "    passive_reward = -1\n",
    "    counting_stars = 0\n",
    "    while passive_reward < 0:\n",
    "        passive_action = passive.next_action(new_state)\n",
    "        game_over, _, _, passive_reward, _, cur_reward = game.take_action(passive_action)\n",
    "        \n",
    "        counting_stars += 1\n",
    "        if counting_stars % 1000 == 0:\n",
    "                print(\"Counting:\", counting_stars)\n",
    "        \n",
    "    if game_over:\n",
    "        return True, old_state, new_state, action, cur_reward\n",
    "    return False, old_state, new_state, action, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(active, passive, memory, batch_size=128):\n",
    "    if len(memory) < batch_size:\n",
    "        return active, passive\n",
    "    \n",
    "    '''batch = memory.sample(batch_size)\n",
    "    # https://stackoverflow.com/a/19343/3343043 --> Batch of transition to transition of batches\n",
    "    batch = Transition(*zip(*batch))\n",
    "    \n",
    "    old_state_batch = torch.cat(batch.old_state)\n",
    "    #print(old_state_batch)\n",
    "    #print(batch.next_state)\n",
    "    next_state_batch = torch.cat(batch.next_state)\n",
    "    #print(next_state_batch)\n",
    "    #action_batch = torch.cat(batch.action)\n",
    "    #reward_batch = torch.cat(batch.reward)\n",
    "    action_batch = torch.stack(batch.action, dim=0)\n",
    "    reward_batch = torch.stack(batch.reward, dim=0)\n",
    "    \n",
    "    #for transition in batch:\n",
    "    #    active.update(*transition)\n",
    "    active.update_batch(old_state_batch, next_state_batch, action_batch, reward_batch)\n",
    "        \n",
    "    model = active.model\n",
    "    active = DeepQPytorchAgent(iterations=iterations, exploration_rate=active.exploration_rate, trained_model=model)\n",
    "    passive = DeepQPytorchAgent(iterations=iterations, exploration_rate=active.exploration_rate, trained_model=model)'''\n",
    "    batch = memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*batch))\n",
    "    old_state_batch = torch.cat(batch.old_state)\n",
    "    action_batch = torch.stack(batch.action, dim=0)\n",
    "    \n",
    "    \n",
    "    # Expected values\n",
    "    #updated_state_values = rewards + (self.discount * next_state_values)\n",
    "    loss = F.smooth_l1_loss(old_state_batch, action_batch.unsqueeze(1))\n",
    "        \n",
    "    active.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # for param in policy_net.parameters():\n",
    "    #    param.grad.data.clamp_(-1, 1)\n",
    "    active.optimizer.step()\n",
    "        \n",
    "    \n",
    "    return active, passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(active, passive, memory, batch_size=128):\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    \n",
    "    batch = memory.sample(batch_size)\n",
    "    \n",
    "    for transition in batch:\n",
    "        active.update(*transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ConnectFourSimulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val = input()\n",
    "while val != \"q\":\n",
    "    game_over, board, _, _, _, _ = game.take_action(int(val))\n",
    "    print(game_over)\n",
    "    game.print_board()\n",
    "    print(\"------------------------------------\")\n",
    "    val = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Input:\", input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#deep_Q_learning = DeepQPytorchAgent(iterations=iterations)\n",
    "#deep_Q_dummy = DeepQPytorchAgent(iterations=iterations)\n",
    "\n",
    "deep_Q_learning = DeepQPytorchAgent(iterations=iterations)\n",
    "deep_Q_dummy = DeepQTensorflowAgent(iterations=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "val = torch.tensor(0).to(device)\n",
    "print(val)\n",
    "print(game.board)\n",
    "game.take_action(val)\n",
    "print(game.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 # Number of games to play\n",
    "batch_size = 64\n",
    "memory = ReplayMemory(10000)\n",
    "active = DeepQPytorchAgent(iterations=epochs*batch_size*20)\n",
    "passive = DeepQPytorchAgent(iterations=epochs*batch_size*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[0]]*6\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].append(2)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_board = np.array([\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "tensor([-0.1906,  0.7001, -0.4927, -0.1696, -0.1241, -0.2168, -0.3087, -0.1187,\n",
      "        -0.0862, -0.3165,  0.8049,  0.4831,  0.1248, -0.1458,  0.3392, -0.0091,\n",
      "        -0.3860,  0.6354,  0.2628, -0.2914, -0.3362, -0.2384,  0.3075, -0.0025,\n",
      "        -0.3406,  0.7256, -0.2759, -0.0552, -0.0388,  0.2600, -0.1204,  0.4795,\n",
      "         0.0804,  0.1824,  0.5297,  0.0537,  0.2202, -0.0201,  0.1331, -0.2096,\n",
      "         0.2440, -0.1686], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(active.next_action(example_board))\n",
    "print(active.get_Q(example_board))\n",
    "print(torch.max(active.get_Q(example_board), 0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n",
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "Time taken: 2239964\n",
      "Time taken in sec: 2239.964\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Using memory replay\n",
    "total_rewards = [ [0] for epoch in range(epochs) ]\n",
    "total = [0]\n",
    "print(total_rewards)\n",
    "start = int(round(time.time() * 1000))\n",
    "for epoch in range(epochs):\n",
    "    #invalids = []\n",
    "    #invalid = 0\n",
    "    #for iteration in range(1, iterations + 1):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    game_over = False\n",
    "    game = ConnectFourSimulator()\n",
    "    while not game_over:\n",
    "        optimize_model(active, passive, memory, batch_size)\n",
    "        passive.model.load_state_dict(active.model.state_dict())\n",
    "            \n",
    "\n",
    "        #if iteration % 100 == 0:\n",
    "        #    invalids.append(invalid)\n",
    "        #    invalid = 0\n",
    "        #if iteration % 250 == 0:\n",
    "        #    print(\"Iteration:\", iteration)\n",
    "                      \n",
    "        game_over, old_state, next_state, action, reward = transition(game, active, passive)\n",
    "        \n",
    "        #old_state = torch.tensor(old_state.flatten(), device=active.device).float()\n",
    "        #next_state = torch.tensor(next_state.flatten(), device=active.device).float()\n",
    "        #action = torch.tensor(action, device=active.device).float()\n",
    "        #reward = torch.tensor(reward, device=active.device).float()\n",
    "        #if reward != -2:\n",
    "        memory.push(old_state, next_state, action, reward)\n",
    "        total_rewards[epoch].append(total_rewards[epoch][-1] + reward)\n",
    "        total.append(total[-1] + reward)\n",
    "end = int(round(time.time() * 1000))\n",
    "print(\"Time taken:\", (end - start))\n",
    "print(\"Time taken in sec:\", (end - start) / 1000)\n",
    "# Time without batching: 657sec (10), 95 (5), 399 (5)\n",
    "# Time with batching: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "45\n",
      "[0, 0, -2, -2, -4, -6, -8, -10, -12, -14, -16, -18, -20, -22, -24, -26, -28, -30, -32, -34, -36, -38, -40, -42, -44, -46, -48, -48, -50, -52, -52, -54, -56, -56, -58, -58, -60, -60, -62, -64, -66, -68, -68, -70, 930]\n"
     ]
    }
   ],
   "source": [
    "print(len(total_rewards))\n",
    "print(len(total_rewards[0]))\n",
    "print(total_rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3829\n",
      "[0, 0, -2, -2, -4, -6, -8, -10, -12, -14, -16, -18, -20, -22, -24, -26, -28, -30, -32, -34, -36, -38, -40, -42, -44, -46, -48, -48, -50, -52, -52, -54, -56, -56, -58, -58, -60, -60, -62, -64, -66, -68, -68, -70, 930, 928, 926, 924, 922, 920, 918, 916, 914, 912, 910, 908, 906, 904, 902, 900, 898, 898, 898, 896, 896, 894, 892, 890, 888, 886, 886, 884, 882, 880, 880, 880, 878, 876, 874, 874, 872, 870, 868, 868, 866, 864, 862, 860, 858, 1858, 1856, 1856, 1854, 1852, 1850, 1848, 1846, 1844, 1844, 1844, 1842, 1842, 1840, 1838, 1836, 1834, 1832, 1830, 1828, 1826, 1826, 1824, 1822, 1822, 1820, 1818, 1816, 1814, 1812, 1812, 1810, 1808, 1806, 1804, 1802, 1800, 1798, 1798, 1796, 1794, 1792, 1790, 1788, 1786, 1784, 1782, 1780, 1778, 1776, 1774, 1772, 1770, 1770, 1768, 1768, 1768, 1766, 1766, 1764, 1762, 1760, 1758, 1756, 1754, 1752, 1750, 1748, 1746, 1744, 1742, 1740, 1738, 1738, 1736, 1734, 1732, 1730, 1728, 1728, 1726, 1724, 1722, 1720, 1718, 1718, 1716, 1714, 1712, 1710, 1708, 1608, 1606, 1604, 1602, 1600, 1598, 1596, 1594, 1592, 1592, 1590, 1590, 1588, 1586, 1584, 1582, 1580, 1578, 1578, 1578, 1576, 1574, 1572, 1570, 1568, 1566, 1564, 1562, 1560, 1558, 1556, 1554, 1552, 1552, 1550, 1548, 1546, 1544, 1542, 1540, 1538, 1536, 1534, 1534, 2534, 2532, 2530, 2528, 2526, 2524, 2522, 2520, 2520, 2518, 2516, 2514, 2512, 2510, 2510, 2508, 2506, 2504, 2502, 2502, 2500, 2498, 2496, 2496, 2494, 2492, 3492, 3490, 3488, 3486, 3484, 3482, 3480, 3478, 3478, 3476, 3476, 3474, 3472, 3470, 3468, 3466, 3464, 3462, 3460, 3458, 3456, 3454, 3452, 3450, 3448, 3446, 3444, 3442, 3440, 3438, 3436, 3434, 3434, 3432, 3432, 3430, 3428, 3426, 3426, 3424, 3422, 3420, 3418, 3416, 3414, 3412, 3410, 3408, 3406, 3404, 3402, 3400, 3398, 3398, 3398, 3396, 3394, 3392, 3390, 3388, 3386, 3384, 3382, 3380, 3378, 3376, 3374, 3372, 3370, 3368, 3366, 3366, 3364, 3362, 3360, 3358, 3356, 3354, 3352, 3350, 3348, 3346, 3344, 3342, 3340, 3338, 3336, 3334, 3332, 3330, 3328, 3326, 3324, 3322, 3320, 3318, 3316, 3314, 3312, 3310, 4310, 4308, 4306, 4306, 4304, 4304, 4302, 4300, 4298, 4296, 4296, 4294, 4292, 4290, 4288, 4286, 4284, 4282, 4280, 4278, 4276, 4274, 4272, 4270, 4268, 4266, 4264, 4262, 4260, 4258, 4256, 4256, 4254, 4252, 4250, 4248, 4246, 4244, 4242, 4240, 4238, 4236, 4234, 4234, 4232, 4230, 4230, 4230, 5230, 5230, 5228, 5226, 5224, 5222, 5220, 5218, 5216, 5214, 5212, 5210, 5208, 5206, 5204, 5202, 5200, 5198, 5198, 5196, 5194, 5192, 5190, 5188, 5186, 5184, 5182, 5180, 5180, 5178, 5176, 5174, 5172, 5170, 5168, 5166, 5166, 5164, 5162, 5160, 5158, 5156, 5154, 5152, 5150, 5148, 5146, 5144, 5142, 5140, 5138, 5136, 5134, 5132, 5130, 5130, 5128, 5126, 5124, 5122, 5120, 5118, 5116, 5116, 5114, 5112, 5110, 5108, 5106, 5104, 5102, 5100, 5098, 5096, 5094, 5092, 5092, 5090, 5088, 5086, 5084, 5082, 5080, 5080, 5078, 5076, 5074, 5072, 5070, 5068, 5066, 5064, 5062, 5060, 5058, 5056, 5054, 5052, 5050, 5048, 5046, 5044, 5042, 5040, 5038, 5036, 5034, 5032, 5030, 5028, 5026, 5024, 5022, 5020, 5018, 5016, 5014, 5012, 5010, 5008, 5006, 5004, 5002, 5000, 4998, 4996, 4994, 4994, 4992, 4990, 4988, 4986, 4984, 4982, 4980, 4978, 4976, 4976, 4974, 4972, 4970, 4968, 4966, 4964, 4962, 4960, 4960, 4958, 4956, 4954, 4952, 4950, 4948, 4946, 4944, 4942, 4940, 4938, 4936, 4934, 4932, 4930, 4928, 4926, 4924, 4922, 4920, 4918, 4916, 4914, 4912, 4910, 4908, 4906, 4904, 4902, 4900, 4898, 4896, 4796, 4796, 4794, 4792, 4790, 4788, 4786, 4784, 4782, 4780, 4778, 4776, 4774, 4772, 4770, 4768, 4766, 4764, 4762, 4760, 4760, 4760, 4758, 4756, 4756, 4754, 4752, 4752, 4750, 4750, 4748, 4746, 4744, 4742, 4740, 4740, 4738, 4736, 4734, 4732, 4730, 4728, 4726, 4724, 4722, 4720, 4718, 4716, 4714, 4712, 4710, 4708, 4708, 4706, 4704, 4702, 4700, 4698, 4696, 4694, 4692, 4690, 4688, 4686, 4684, 4682, 4680, 4678, 5678, 5678, 5676, 5674, 5672, 5670, 5668, 5666, 5664, 5662, 5660, 5658, 5656, 5654, 5652, 5650, 5648, 5646, 5644, 5642, 5642, 5640, 5638, 5636, 5634, 5632, 5630, 5628, 5626, 5624, 5622, 5620, 5618, 5616, 5614, 5612, 5610, 5608, 5606, 5604, 5604, 5602, 5600, 5600, 5598, 5596, 5594, 5592, 5592, 5590, 5588, 5586, 5584, 5582, 5580, 5578, 5576, 5574, 5572, 5570, 5568, 5566, 5564, 5562, 5560, 5558, 5556, 5554, 5552, 5550, 5548, 5546, 5544, 5542, 5540, 5540, 5538, 5536, 5534, 5532, 5530, 5528, 5526, 5524, 5522, 5520, 5518, 5516, 5514, 5512, 5510, 5508, 5506, 5504, 5502, 5500, 5498, 5496, 5494, 5492, 5490, 5488, 5486, 5484, 5482, 5480, 5478, 5378, 5376, 5374, 5374, 5372, 5370, 5368, 5366, 5364, 5364, 5362, 5360, 5358, 5356, 5356, 5354, 5352, 5350, 5348, 5346, 5344, 5342, 5340, 5338, 5336, 5334, 5332, 5330, 5328, 5326, 5326, 5324, 5322, 5320, 5318, 5316, 5314, 5312, 5312, 5310, 5308, 5306, 5304, 5302, 5300, 5298, 5296, 5294, 5292, 5290, 5288, 5286, 5284, 5282, 5280, 5278, 5276, 5274, 5272, 5270, 5268, 5266, 5264, 5262, 5260, 5258, 5256, 5254, 5252, 5250, 5248, 5246, 5244, 5242, 5240, 5238, 5236, 5234, 5232, 5230, 5228, 5226, 5224, 5222, 5220, 5218, 5216, 5214, 5212, 5210, 5208, 5206, 5204, 5204, 5202, 5200, 5198, 5198, 5196, 5194, 5192, 5190, 5188, 5186, 5184, 5182, 5180, 5178, 5176, 5174, 5172, 5170, 5170, 5168, 5166, 5164, 5162, 5160, 5158, 5156, 5154, 5152, 5150, 5148, 5146, 5144, 5142, 5140, 5138, 5136, 5134, 5132, 5130, 5128, 5126, 5126, 5124, 5122, 5120, 5120, 5118, 5116, 5114, 5112, 5110, 5108, 5106, 5106, 5104, 5102, 6102, 6100, 6098, 6096, 6096, 6094, 6092, 6090, 6088, 6086, 6084, 6082, 6080, 6078, 6076, 6074, 6072, 6070, 6068, 6066, 6064, 6062, 6060, 6058, 6056, 6054, 6052, 6050, 6048, 6046, 6044, 6042, 6040, 6038, 6036, 6034, 6034, 6032, 6030, 6028, 6026, 6026, 6024, 6024, 6022, 6020, 6018, 6016, 6014, 6012, 6010, 6008, 6006, 6004, 6002, 6000, 5998, 5996, 5994, 5992, 5990, 5988, 5986, 5984, 5982, 5980, 5978, 5976, 5974, 5972, 5970, 5968, 5966, 5964, 5962, 5960, 5958, 5956, 5954, 5952, 5950, 5948, 5946, 5944, 5942, 5940, 5938, 5936, 5934, 5934, 5932, 5930, 5928, 5928, 5926, 5924, 5922, 5920, 5918, 5916, 5914, 5912, 5910, 5908, 5906, 5904, 5902, 5902, 5900, 5898, 5896, 5894, 5892, 5892, 5890, 5888, 5886, 5884, 5884, 5882, 5880, 5878, 5876, 5874, 5872, 5870, 5868, 5866, 5864, 5862, 5860, 5860, 5858, 5856, 5854, 5852, 5850, 5848, 5846, 5844, 5842, 5840, 5838, 5836, 5834, 5832, 5830, 5828, 5826, 5824, 5822, 5820, 5818, 5816, 5814, 5812, 5810, 5808, 5806, 6806, 6804, 6802, 6800, 6798, 6796, 6794, 6792, 6790, 6788, 6786, 6784, 6782, 6782, 6780, 6778, 6776, 6774, 6772, 6770, 6768, 6766, 6764, 6762, 6760, 6758, 6756, 6754, 6752, 6750, 6748, 6748, 6746, 6744, 6742, 6740, 6738, 6736, 6734, 6732, 6730, 6728, 6726, 6724, 6722, 6720, 6718, 6718, 6716, 6714, 6712, 6710, 6708, 6706, 6704, 6702, 6700, 6700, 6698, 6696, 6694, 6692, 6690, 6688, 6686, 6684, 6682, 6680, 6678, 6676, 6674, 6672, 6670, 6668, 6666, 6664, 6662, 6660, 6658, 6656, 6654, 6652, 6650, 6650, 6648, 6646, 6644, 6642, 6640, 6638, 6636, 6634, 6632, 6630, 6628, 6626, 6624, 6622, 6620, 6618, 6616, 6614, 6612, 6610, 6610, 6608, 6606, 6604, 6604, 6602, 6600, 6598, 6596, 6594, 6592, 6590, 6588, 6586, 6584, 6582, 6580, 6578, 6576, 6574, 6572, 6572, 6570, 6570, 6568, 6566, 6564, 6562, 6462, 6462, 6462, 6460, 6460, 6458, 6456, 6454, 6452, 6450, 6448, 6448, 6446, 6444, 6442, 6440, 6438, 6436, 6434, 6432, 6430, 6428, 6426, 6424, 6422, 6420, 6418, 6416, 6414, 6412, 6410, 6408, 6406, 6406, 6404, 6402, 6400, 6398, 6396, 6396, 6396, 6394, 6392, 6390, 6388, 6386, 6384, 6382, 6380, 6378, 6376, 6376, 6374, 6372, 6370, 6368, 6366, 6364, 6362, 6360, 6358, 6356, 6354, 6352, 6352, 6350, 6348, 6346, 6344, 6342, 6340, 6338, 6336, 6334, 6332, 6330, 6328, 6326, 6324, 6322, 6322, 6320, 6318, 6316, 6314, 6312, 6310, 6308, 6306, 6304, 6302, 6300, 6298, 6296, 6294, 6292, 6290, 6288, 6288, 6286, 6284, 6282, 6280, 6280, 6278, 6276, 6274, 6272, 6270, 6268, 6266, 6264, 6262, 6260, 6258, 6256, 6254, 6252, 6250, 6248, 6246, 6244, 6242, 7242, 7240, 7238, 7238, 7236, 7234, 7232, 7230, 7228, 7226, 7224, 7222, 7220, 7220, 7218, 7216, 7214, 7214, 7212, 7210, 7208, 7206, 7206, 7204, 7202, 7200, 7198, 7196, 7194, 7192, 7190, 7188, 7186, 7184, 7182, 7180, 7178, 7176, 7176, 7174, 7172, 7170, 7168, 7166, 7164, 7162, 7160, 7158, 7156, 7154, 7152, 7150, 7150, 7148, 7146, 7144, 7142, 7140, 7140, 7138, 7136, 7134, 7132, 7130, 7128, 7128, 7126, 7124, 7122, 7120, 7118, 7116, 7114, 7112, 7110, 7110, 7108, 7106, 7106, 7104, 7102, 7100, 7100, 7098, 7096, 7094, 7092, 7090, 7088, 7086, 7084, 7082, 7080, 7078, 7076, 7074, 7072, 7070, 7068, 7066, 7064, 7062, 7060, 7058, 7056, 7054, 7052, 7050, 7050, 7048, 7046, 7044, 7042, 7040, 7038, 7036, 7034, 7032, 7030, 7028, 7026, 7024, 7022, 7020, 7018, 7016, 7014, 7012, 7010, 7008, 7006, 7004, 7002, 7000, 6998, 6996, 6994, 6992, 6990, 6988, 6986, 6984, 6982, 6980, 6978, 6976, 6974, 6972, 6970, 6968, 6966, 6964, 6962, 6960, 6958, 6956, 6954, 6952, 6950, 6948, 6946, 6944, 6942, 7942, 7940, 7940, 7938, 7936, 7934, 7932, 7930, 7928, 7926, 7924, 7922, 7920, 7918, 7916, 7914, 7912, 7912, 7910, 7910, 7908, 7906, 7904, 7902, 7900, 7898, 7896, 7896, 7894, 7892, 7890, 7888, 7886, 7884, 7882, 7880, 7880, 7880, 7878, 7876, 7874, 7872, 7872, 7870, 7868, 7866, 7864, 7862, 7860, 7858, 7858, 7856, 7854, 7852, 7850, 7848, 7846, 7844, 7842, 7840, 7838, 7836, 7834, 7832, 7830, 7828, 7826, 7824, 7822, 7820, 7818, 7816, 7814, 7814, 7814, 7812, 7810, 7808, 7806, 7804, 7802, 7800, 7798, 7796, 7794, 7792, 7790, 7788, 7786, 7784, 7782, 7780, 7778, 7776, 7776, 7774, 7772, 7770, 7768, 7766, 7764, 7762, 7760, 7758, 7756, 7754, 7752, 7750, 7748, 7746, 7744, 7742, 7740, 7738, 7736, 7734, 7634, 7632, 7630, 7628, 7626, 7624, 7622, 7620, 7620, 7618, 7616, 7614, 7612, 7610, 7608, 7606, 7604, 7602, 7600, 7598, 7596, 7594, 7592, 7590, 7588, 7586, 7584, 7582, 7580, 7578, 7576, 7574, 7572, 7572, 7570, 7568, 7568, 7566, 7564, 7562, 7560, 7558, 7558, 7556, 7554, 7554, 7552, 7550, 7548, 7546, 7544, 7542, 7540, 7538, 7536, 7534, 7532, 7530, 7528, 7526, 7526, 7524, 7522, 7522, 7520, 7518, 7516, 7514, 7512, 7510, 7508, 7506, 7506, 7504, 7502, 7500, 7498, 7496, 7494, 7492, 7492, 7490, 7488, 7486, 7484, 7482, 7480, 7478, 7478, 7476, 7474, 7472, 7470, 7468, 7466, 7464, 7462, 7460, 7458, 7456, 7454, 7452, 7450, 7448, 7446, 7444, 7442, 7442, 7440, 7438, 7436, 7434, 7432, 7430, 7428, 7426, 7424, 7422, 7420, 7418, 7416, 7414, 7412, 7410, 7408, 7406, 7404, 7402, 8402, 8402, 8400, 8398, 8396, 8394, 8394, 8392, 8390, 8388, 8388, 8386, 8384, 8382, 8380, 8378, 8376, 8374, 8372, 8370, 8368, 8366, 8364, 8362, 8360, 8358, 8356, 8354, 8352, 8352, 8350, 8350, 9350, 9348, 9346, 9346, 9344, 9342, 9340, 9338, 9336, 9334, 9332, 9330, 9328, 9326, 9324, 9324, 9322, 9320, 9318, 9316, 9314, 9312, 9310, 9308, 9306, 9304, 9302, 9300, 9298, 9298, 9296, 9294, 9292, 9290, 9288, 9286, 9284, 9282, 9280, 9278, 9276, 9274, 9272, 9270, 9270, 9268, 9266, 9264, 9262, 9260, 9258, 9256, 9254, 9254, 9252, 9250, 9248, 9246, 9246, 9244, 9242, 9240, 9238, 9236, 9234, 9232, 9230, 9228, 9226, 9224, 9224, 9222, 9220, 9218, 9216, 9214, 9212, 9210, 9208, 9206, 9204, 9204, 9202, 9200, 9200, 9198, 9196, 9194, 9192, 9192, 9190, 9188, 9186, 9184, 9182, 9180, 9178, 9176, 9174, 9172, 9170, 9168, 9166, 9164, 9162, 9160, 9158, 9156, 9154, 9152, 9150, 9148, 9146, 9144, 9142, 9140, 9138, 9138, 9136, 9134, 9132, 9130, 9128, 9126, 9124, 9122, 9120, 9118, 9116, 9114, 9112, 9110, 9110, 9108, 9106, 9104, 9102, 9100, 9098, 9096, 9094, 9092, 9090, 9088, 9086, 9084, 9082, 9080, 10080, 10078, 10078, 10078, 10076, 10076, 10074, 10072, 10070, 10068, 10066, 10064, 10062, 10060, 10058, 10056, 10054, 10052, 10050, 10048, 10046, 10044, 10042, 10040, 10040, 10038, 10036, 10036, 10034, 10032, 10030, 10028, 10026, 10024, 10022, 10020, 10018, 10016, 10014, 10012, 10010, 10008, 10006, 10004, 10002, 10000, 9998, 9996, 9994, 9992, 9990, 9988, 9986, 9984, 9984, 9982, 9980, 9980, 9978, 9976, 9974, 9972, 9970, 9968, 9966, 9964, 9962, 9960, 9958, 9956, 9954, 9952, 9950, 9948, 9946, 9944, 9942, 9940, 9938, 9936, 9934, 9934, 9932, 9930, 9928, 9926, 9924, 9922, 9920, 9918, 9916, 9914, 9912, 9910, 9908, 9906, 9904, 9902, 9900, 9898, 9896, 9894, 9892, 9892, 9890, 9888, 9886, 9884, 9882, 9880, 9878, 9876, 9874, 9872, 9870, 9770, 9768, 9766, 9764, 9762, 9760, 9758, 9758, 9756, 9754, 9752, 9750, 9748, 9746, 9744, 9742, 9740, 9738, 9736, 9734, 9732, 9730, 9728, 9728, 9726, 9724, 9722, 9720, 9720, 9720, 9720, 9718, 9716, 9714, 9712, 9710, 9710, 9708, 9708, 9706, 9704, 9702, 9700, 9698, 9696, 9694, 9692, 9690, 9688, 9686, 9686, 9684, 9684, 9682, 9680, 9678, 9676, 9674, 9672, 9670, 9668, 9666, 9664, 9662, 9660, 9658, 9656, 9654, 9652, 9650, 9648, 9646, 9644, 9642, 9640, 9638, 9636, 9634, 9632, 9630, 9628, 9626, 9624, 9622, 9620, 9618, 9616, 9616, 9616, 9614, 9612, 9610, 9608, 9606, 9604, 9602, 9600, 9598, 9596, 9594, 9592, 9590, 10590, 10588, 10586, 10584, 10582, 10580, 10578, 10576, 10576, 10574, 10572, 10570, 10568, 10566, 10564, 10562, 10562, 10560, 10558, 10556, 10554, 10552, 10550, 10548, 10548, 10546, 10544, 10542, 10540, 10538, 10536, 10534, 10532, 10532, 10530, 10528, 10528, 10526, 10524, 10522, 10520, 10518, 10516, 10514, 10512, 10510, 10508, 10506, 10504, 10502, 10500, 10498, 10496, 10494, 10492, 10492, 10490, 10488, 10486, 10484, 10482, 10480, 10478, 10476, 10476, 10476, 10474, 10472, 10470, 10468, 10466, 10464, 10462, 10460, 10458, 10456, 10454, 10452, 10450, 10448, 10446, 10444, 10442, 10440, 10438, 10436, 10434, 10432, 10430, 10428, 10426, 10424, 10422, 10420, 10418, 10416, 10414, 10412, 10410, 10408, 10406, 10404, 10402, 10400, 10398, 10396, 10394, 10392, 10390, 10388, 10386, 10384, 10382, 10380, 10380, 10378, 10376, 10374, 10372, 10370, 10368, 10366, 10364, 10362, 10360, 10358, 10356, 10354, 10352, 10350, 10348, 10348, 10346, 10344, 10342, 10340, 10338, 10336, 10334, 10332, 10330, 10328, 10326, 10324, 10322, 10320, 10318, 10318, 10318, 10318, 10316, 10314, 10312, 10310, 10308, 10306, 10304, 10302, 10300, 10298, 10296, 10294, 10292, 10290, 10288, 10286, 10284, 10282, 10280, 10278, 10276, 10274, 10272, 10272, 10270, 10268, 10266, 10264, 10262, 10260, 10258, 10256, 10254, 10252, 10250, 10248, 10246, 10244, 10242, 10240, 10238, 10236, 10234, 10234, 10232, 10230, 10228, 10226, 10224, 10224, 10222, 10222, 10220, 10218, 10216, 10214, 10212, 10210, 10208, 10206, 10204, 10202, 10200, 10198, 10196, 10194, 10192, 10190, 10188, 10186, 10184, 10182, 10180, 10178, 10176, 10174, 10172, 10170, 10168, 10166, 10164, 10162, 10160, 10158, 10156, 10154, 10152, 10150, 10148, 10146, 10144, 10142, 10140, 10138, 10136, 10134, 10132, 10130, 10128, 10126, 10124, 10122, 10120, 10118, 10116, 10114, 10112, 10110, 10108, 10106, 10104, 10102, 10100, 10098, 10096, 10094, 10092, 10090, 10088, 10086, 10084, 10082, 10080, 10078, 10076, 10074, 10072, 10070, 10068, 10066, 10064, 10062, 10060, 10058, 10058, 10056, 10054, 10052, 10050, 10048, 10046, 10044, 10042, 10040, 10038, 10036, 10034, 10032, 10030, 10028, 10026, 10024, 10022, 10020, 10018, 10016, 10014, 10012, 10010, 10008, 10006, 10004, 10002, 10000, 9998, 9996, 9994, 9992, 9990, 9988, 9986, 9984, 9982, 9980, 9978, 9976, 9974, 9972, 9970, 9968, 9966, 9964, 9962, 9960, 9958, 9956, 9954, 9952, 9950, 9948, 9946, 9944, 9942, 9940, 9938, 9936, 9934, 9932, 9930, 9928, 9926, 9924, 9922, 9920, 9918, 9916, 9816, 9814, 9812, 9810, 9808, 9806, 9804, 9802, 9800, 9798, 9796, 9796, 9794, 9792, 9790, 9790, 9788, 9786, 9784, 9782, 9780, 9778, 9778, 9776, 9774, 9772, 9772, 9770, 9768, 9766, 9764, 9762, 9760, 9758, 9756, 9754, 9752, 9750, 9748, 9746, 9744, 9742, 9740, 9738, 9738, 9736, 9734, 9732, 9730, 9728, 9726, 9724, 9724, 9722, 9720, 9718, 9716, 9714, 9712, 9710, 9708, 9706, 9704, 9702, 9700, 9698, 9696, 9694, 9692, 9690, 9688, 9686, 9684, 9682, 9680, 9678, 9676, 9674, 9672, 9670, 9668, 9668, 9666, 9666, 9664, 9662, 9662, 9662, 9660, 9658, 9656, 9654, 9652, 9650, 9648, 9646, 9644, 9642, 9640, 9638, 9636, 9634, 9634, 9632, 9630, 9628, 9628, 9626, 9624, 9622, 9620, 9618, 9616, 9614, 9612, 9610, 9608, 9606, 9604, 9602, 9600, 9598, 9596, 9594, 9592, 9590, 9588, 9586, 9584, 9582, 9580, 9578, 9576, 9574, 9572, 9570, 9568, 9566, 9564, 9562, 9560, 9560, 9558, 9556, 9556, 9554, 9552, 9550, 9548, 9546, 9544, 9542, 9540, 9538, 9536, 9534, 9532, 9530, 9528, 9526, 9524, 9522, 9520, 9518, 9516, 9514, 9512, 9510, 9508, 9508, 9508, 9506, 9504, 9502, 9500, 9498, 9496, 9494, 9492, 9490, 9488, 9486, 9484, 9482, 9480, 9478, 9476, 9474, 9472, 9470, 9468, 9466, 9466, 9464, 9462, 9460, 9458, 9456, 9454, 9452, 9450, 9448, 9446, 9444, 9442, 9440, 9438, 9436, 9434, 9432, 9432, 9430, 9428, 9426, 9424, 9422, 9420, 9418, 9416, 9414, 9412, 9410, 9408, 9406, 9404, 9402, 9400, 9398, 9396, 9394, 9392, 9390, 9388, 9386, 9384, 9382, 9380, 9378, 9376, 9374, 9372, 9370, 9368, 9366, 9364, 9362, 9360, 9358, 9356, 9354, 9352, 9350, 9348, 9346, 9344, 9342, 9340, 9338, 9336, 9334, 9332, 9330, 9328, 9326, 9324, 9322, 9320, 9318, 9316, 9314, 9312, 9310, 9308, 9306, 9304, 9302, 9300, 9298, 9296, 9294, 9292, 9290, 9288, 9286, 9284, 9284, 9282, 9280, 9278, 9276, 9274, 9272, 9270, 9268, 9266, 9264, 9262, 9260, 9258, 9256, 9254, 9252, 9250, 9248, 9246, 9244, 9242, 9240, 9238, 9236, 9234, 9232, 9230, 9228, 9226, 9224, 9222, 9220, 9218, 9216, 9214, 9212, 9210, 9208, 9206, 9204, 9202, 9200, 9198, 9196, 9194, 9192, 9190, 9188, 9186, 9184, 9182, 9180, 9178, 9176, 9174, 9172, 9170, 9168, 9166, 9164, 9162, 9160, 9158, 9156, 9154, 9152, 9150, 9148, 9146, 9144, 9142, 9140, 9138, 9136, 9134, 9132, 9130, 9128, 9126, 9124, 9122, 9120, 9118, 9116, 9114, 9112, 9110, 9108, 9106, 9104, 9102, 9100, 9098, 9096, 9094, 9092, 9090, 9088, 9086, 9084, 9082, 9080, 9078, 9076, 9074, 9072, 9070, 9068, 9066, 9064, 9062, 9060, 9058, 9056, 9054, 9052, 9050, 9048, 9046, 9044, 9042, 9040, 9038, 9036, 9034, 9032, 10032, 10030, 10030, 10030, 10028, 10026, 10024, 10022, 10020, 10018, 10016, 10014, 10012, 10012, 10010, 10008, 10008, 10006, 10004, 10002, 10000, 9998, 9996, 9996, 9994, 9992, 9990, 9988, 9988, 9986, 9984, 9982, 9980, 9978, 9976, 9974, 9972, 9970, 9968, 9966, 9964, 9962, 9960, 9960, 9958, 9956, 9954, 9952, 9950, 9948, 9946, 9944, 9944, 9942, 9940, 9938, 9936, 9934, 9932, 9930, 9928, 9926, 9924, 9922, 9920, 9918, 9916, 9914, 9912, 9910, 9908, 9906, 9904, 9902, 9900, 9898, 9896, 9894, 9892, 9892, 9890, 9888, 9886, 9884, 9884, 9882, 9880, 9878, 9876, 9874, 9872, 9870, 9868, 9866, 9864, 9862, 9860, 9858, 9856, 9854, 9852, 9852, 9850, 9848, 9848, 9846, 9844, 9842, 9840, 9838, 9836, 9834, 9832, 9830, 9828, 9826, 9824, 9822, 9820, 9720, 9720, 9718, 9716, 9716, 9714, 9712, 9710, 9710, 9708, 9708, 9706, 9704, 9702, 9700, 9698, 9696, 9694, 9692, 9690, 9690, 9688, 9686, 9684, 9682, 9680, 9678, 9676, 9674, 9672, 9670, 9668, 9666, 9664, 9662, 9662, 9660, 9658, 9656, 9654, 9652, 9650, 9648, 9646, 9644, 9642, 9640, 9638, 9636, 9634, 9634, 9632, 9630, 9628, 9528, 9526, 9524, 9522, 9520, 9518, 9516, 9516, 9514, 9512, 9510, 9510, 9508, 9506, 9506, 9504, 9502, 9500, 9498, 9496, 9494, 9492, 9490, 9488, 9488, 9486, 9484, 9482, 9480, 9478, 9476, 9474, 9472, 9470, 9468, 9466, 9464, 9462, 9460, 9460, 9458, 9456, 9456, 9454, 9452, 9452, 9450, 9448, 9446, 9444, 9444, 9442, 9440, 9438, 9436, 9434, 9432, 9430, 9428, 9426, 9424, 9424, 9422, 9420, 9418, 9416, 9414, 9412, 9410, 9408, 9406, 9404, 9402, 9400, 9398, 9398, 9398, 9396, 9394, 9392, 9390, 9388, 9388, 9386, 9384, 9384, 9382, 9380, 9378, 9376, 9374, 9372, 9370, 9368, 9366, 9364, 9362, 9360, 9358, 9356, 9354, 9352, 9350, 9348, 9346, 9344, 9342, 9340, 9338, 9336, 9334, 9334, 9332, 9330, 9328, 9326, 9324, 9322, 9320, 9318, 9316, 9314, 9312, 9310, 9308, 9306, 9304, 9302, 9302, 9300, 9298, 9296, 9294, 9292, 9290, 9288, 9286, 9284, 9282, 9280, 9278, 9276, 9274, 9272, 9272, 9270, 9268, 9266, 9264, 9262, 9260, 9258, 9256, 9254, 9252, 9250, 9248, 9246, 9244, 9242, 9240, 9238, 9236, 9234, 9232, 9230, 9228, 9226, 9224, 9222, 9220, 9218, 9216, 9216, 9214, 9212, 9210, 9208, 9206, 9204, 9202, 9200, 9198, 9196, 9194, 9192, 9190, 9188, 9186, 9184, 9182, 9180, 9178, 9176, 9174, 9172, 9170, 9168, 9166, 9164, 9162, 9160, 9158, 9156, 9154, 9152, 9150, 9148, 9146, 9144, 9142, 9140, 9138, 9136, 9134, 9132, 9130, 9128, 9126, 9124, 9122, 9120, 9118, 9116, 9114, 9112, 9110, 9108, 9106, 9104, 9102, 9100, 9098, 9096, 9094, 9092, 9090, 9088, 9086, 9084, 9082, 9080, 9078, 9076, 9074, 9072, 9070, 9068, 9066, 9064, 9062, 9060, 9058, 9056, 9054, 9052, 9050, 9048, 9046, 9044, 9042, 9040, 9038, 9036, 9034, 9034, 9032, 9030, 9028, 9026, 9024, 9022, 9020, 9018, 9016, 9016, 9014, 9012, 9010, 9008, 9006, 9004, 9002, 9000, 8998, 8996, 8994, 8992, 8990, 8988, 8986, 8984, 8982, 8980, 8978, 8976, 8974, 8972, 8970, 8968, 8966, 8964, 8962, 8960, 8958, 8956, 8954, 8952, 8950, 8948, 8946, 8944, 8942, 8940, 8940, 8938, 8938, 8936, 8936, 8934, 8932, 8930, 8928, 8926, 8924, 8922, 8920, 8918, 8916, 8914, 8912, 8910, 8910, 8910, 8908, 8906, 8904, 8902, 8900, 8898, 8896, 8894, 8892, 8890, 8888, 8886, 8884, 8882, 8882, 8882, 8880, 8880, 8878, 8876, 8874, 8872, 8872, 8870, 8868, 8866, 8864, 8862, 8860, 8858, 8856, 8854, 8852, 8850, 8848, 8846, 8844, 8842, 8842, 8840, 8838, 8836, 8834, 8832, 8830, 8828, 8826, 8824, 8822, 8820, 8818, 8816, 8814, 8812, 8810, 8808, 8806, 8804, 8802, 8800, 8798, 8796, 8794, 8792, 8790, 8788, 8786, 8784, 8782, 8780, 8778, 8776, 8774, 8772, 8770, 8768, 8768, 8766, 8764, 8764, 8762, 8760, 8760, 8758, 8758, 8758, 8756, 8754, 8752, 8750, 8748, 8746, 8744, 8742, 8740, 8738, 8736, 8734, 8732, 8730, 8728, 8726, 8724, 8624, 8622, 8622, 8620, 8618, 8616, 8614, 8612, 8610, 8608, 8606, 8604, 8602, 8602, 8602, 8600, 8598, 8596, 8594, 8592, 8590, 8590, 8588, 8586, 8584, 8582, 8580, 8578, 8578, 8576, 8574, 8572, 8570, 8568, 8566, 8564, 8564, 8562, 8560, 8558, 8556, 8556, 8554, 8552, 8550, 8548, 8546, 8546, 8544, 8542, 8540, 8538, 8536, 8534, 8534, 8532, 8532, 8530, 8528, 8526, 8524, 8522, 8520, 8518, 8516, 8514, 8512, 8510, 8508, 8506, 8504, 8502, 8500, 8498, 8496, 8494, 8494, 8492, 8490, 8488, 8486, 8484, 8484, 8482, 8480, 8480, 8478, 8476, 8474, 8472, 8470, 8468, 8466, 8464, 8462, 8460, 8458, 8456, 8454, 8452, 8450, 8450, 8448, 8446, 8444, 8442, 8440, 8438, 8436, 8436, 8434, 8432, 8332, 8330, 8330, 8328, 8326, 8324, 8322, 8320, 8318, 8316, 8314, 8312, 8310, 8308, 8308, 8308, 8306, 8304, 8302, 8300, 8298, 8296, 8294, 8292, 8290, 8288, 8288, 8286, 8284, 8284, 8282, 8280, 8278, 8276, 8274, 8272, 8270, 8268, 8268, 8266, 8264, 8262, 8260, 8258, 8258, 8256, 8254, 8252, 8250, 8248, 8246, 8244, 8242, 8240, 8238, 8238, 8236, 8234, 8232, 8230, 8228, 8226, 8224, 8222, 8220, 8218, 8216, 8216, 8214, 8212, 8210, 8208, 8206, 8206, 8204, 8202, 8200, 8198, 8196, 8194, 8192, 8190, 8188, 8186, 8184, 8182, 8180, 8180, 8178, 8176, 8174, 8172, 8172, 8170, 8168, 8166, 8164, 8162, 9162, 9160, 9158, 9156, 9154, 9152, 9152, 9150, 9148, 9146, 9144, 9142, 9142, 9142, 9140, 9138, 9138, 9136, 9134, 9132, 9130, 9128, 9126, 9124, 9122, 9120, 9118, 9118, 9116, 9114, 9112, 9110, 9108, 9106, 9104, 9102, 9100, 9100, 9098, 9096, 9094, 9092, 9090, 9088, 9086, 9084, 9082, 9082, 9080, 9078, 9076, 9074, 9072, 9070, 9068, 9066, 9064, 9062, 9062, 9060, 9058, 9056, 9054, 9052, 9050, 9048, 9046, 9044, 9042, 9042, 9040, 9038, 9036, 9034, 9032, 9030, 9028, 9026, 9026, 9024, 9022, 9020, 9018, 9016, 9014, 9012, 9010, 9008, 9006, 9004, 9002, 9000, 8998, 8996, 8994, 8992, 8990, 8988, 8986, 8984, 8982, 8980, 8980, 8978, 8976, 8974, 8972, 8970, 8968, 8966, 8964, 8962, 8960, 8958, 8956, 8954, 8952, 8950, 8948, 8946, 9946]\n"
     ]
    }
   ],
   "source": [
    "print(len(total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x5563d68>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "#plt.plot(total_rewards[0])\n",
    "plt.plot(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(invalids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invalids = []\n",
    "invalid = 0\n",
    "for step in range(10000):\n",
    "    if step % 250 == 0:\n",
    "        print(\"Still running at iteration\", step)\n",
    "        \n",
    "    \n",
    "    old_state = game.board\n",
    "    action = deep_Q_learning.next_action(old_state)\n",
    "    game_over, new_state, cur_player, cur_reward, _, _ = game.take_action(action)\n",
    "    \n",
    "    if (step + 1) % 100 == 0:\n",
    "            invalids.append(invalid)\n",
    "            invalid = 0\n",
    "    if cur_reward < 0: # Invalid action\n",
    "        deep_Q_learning.update(old_state, new_state, action, cur_reward)\n",
    "        invalid += 1\n",
    "        continue\n",
    "        \n",
    "    #print(game_over)\n",
    "    #print(new_state)\n",
    "    #print(cur_player)\n",
    "    #print(cur_reward)\n",
    "    \n",
    "    if game_over:\n",
    "        deep_Q_learning.update(old_state, new_state, action, cur_reward)\n",
    "        game = ConnectFourSimulator()\n",
    "        continue\n",
    "    \n",
    "    next_action = deep_Q_dummy.next_action(new_state)\n",
    "    game_over, next_state, _, active_reward, passive_player, passive_reward = game.take_action(action)\n",
    "    \n",
    "    counting_stars = 0\n",
    "    while active_reward < 0: # Invalid move (infinite loop possible?)\n",
    "        next_action = deep_Q_dummy.next_action(new_state)\n",
    "        game_over, next_state, _, active_reward, passive_player, passive_reward = game.take_action(next_action)\n",
    "        counting_stars += 1\n",
    "        if counting_stars % 1000 == 0:\n",
    "            print(\"Counting:\", counting_stars)\n",
    "            print(\"Using action:\", action)\n",
    "    \n",
    "    #print(game_over)\n",
    "    #print(next_state)\n",
    "    #print(passive_player)\n",
    "    #print(passive_reward)\n",
    "    \n",
    "    if game_over:\n",
    "        deep_Q_learning.update(old_state, new_state, action, passive_reward)\n",
    "        game = ConnectFourSimulator()\n",
    "    else:\n",
    "        deep_Q_learning.update(old_state, new_state, action, cur_reward)\n",
    "    # Missing: check for invalid move\n",
    "    # Maybe add passive mode to game (for the 2nd player)\n",
    "    #print(\"----------------------------\")\n",
    "        \n",
    "print(\"Invalids:\", invalids)\n",
    "print(\"Total:\", sum(invalids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error in the end comes from the network predicting a result, which is wrong and since exploration is way down it almost\n",
    "# always predicts the same action which is always wrong. Should somehow learn though (maybe replay necessary?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- Use memory replay --> DONE\n",
    "- Maybe higher rewards needed for backpropagation of Q values?\n",
    "- View reward function by playing vs the network\n",
    "- View network output for certain states\n",
    "<br>\n",
    "<br>\n",
    "- Do I even backpropagate the reward to other states than the winning one in any way?\n",
    "- Maybe the problem are few games (not enough possibilities learned) -> More iterations like 10_000 games instead of iterations\n",
    "- Learning rate?\n",
    "<br>\n",
    "<br>\n",
    "- Rework memory replay batch size and epochs analog to pytorch tutorial\n",
    "- Plot metrics (e.g. total reward every iteration)\n",
    "- Rework code --> Readability and reusability\n",
    "- Maybe rework greedy policy\n",
    "- Test the pytorch agent on the dungeon example --> DONE: Works\n",
    "- Try increasing the performance (For running in the cloud) -> Use timer\n",
    "- Maybe no punishment for invalid moves?\n",
    "- Pass possible moves to network?\n",
    "- Only give out copies of the state... --> FIXED (This literally ruined every single state in the memory...)\n",
    "- Copy pytorch tensors via .copy().detach() (maybe more effectively possible as well?)\n",
    "<br>\n",
    "<br>\n",
    "- How to choose rewards and how does the agent learn the rules (punishment for invalid moves?)\n",
    "- How much training is needed for a game?\n",
    "- Evaluation tactics: Total reward\n",
    "- Model too big?\n",
    "- Don't copy model to update agent? --> Constantly creating optimizer and agent again and again\n",
    "- Only learning negative values atm --> Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_board = np.zeros(shape=(6, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_board = np.array([\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0]\n",
    "])\n",
    "example_board2 = np.array([\n",
    "    [0,0,1,1,-1,0,0],\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,1,-1,0,0],\n",
    "    [0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "tensor([-34.1751, -34.0506, -34.2195, -34.0886, -34.1386, -34.0437, -34.0337,\n",
      "        -34.1965, -33.9976, -34.0872, -34.1709, -34.2188, -34.1696, -34.2562,\n",
      "        -34.0796, -34.2120, -34.1064, -33.8299, -34.1041, -34.3281, -34.2597,\n",
      "        -34.2649, -34.2695, -34.2441, -34.2201, -34.2743, -34.2059, -34.2161,\n",
      "        -34.2505, -34.2161, -34.2206, -34.0410, -34.2127, -34.2098, -34.2600,\n",
      "        -34.1673, -34.1112, -34.1166, -34.1670, -34.1881, -34.2099, -34.2906],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(active.next_action(example_board))\n",
    "print(active.get_Q(example_board))\n",
    "print(torch.max(active.get_Q(example_board), 0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "tensor([-34.1751, -34.0506, -34.2195, -34.0886, -34.1386, -34.0437, -34.0337,\n",
      "        -34.1965, -33.9976, -34.0872, -34.1709, -34.2188, -34.1696, -34.2562,\n",
      "        -34.0796, -34.2120, -34.1064, -33.8299, -34.1041, -34.3281, -34.2597,\n",
      "        -34.2649, -34.2695, -34.2441, -34.2201, -34.2743, -34.2059, -34.2161,\n",
      "        -34.2505, -34.2161, -34.2206, -34.0410, -34.2127, -34.2098, -34.2600,\n",
      "        -34.1673, -34.1112, -34.1166, -34.1670, -34.1881, -34.2099, -34.2906],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(active.next_action(example_board2))\n",
    "print(active.get_Q(example_board2))\n",
    "print(torch.max(active.get_Q(example_board2), 0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "tensor([-34.1751, -34.0506, -34.2195, -34.0886, -34.1386, -34.0437, -34.0337,\n",
      "        -34.1965, -33.9976, -34.0872, -34.1709, -34.2188, -34.1696, -34.2562,\n",
      "        -34.0796, -34.2120, -34.1064, -33.8299, -34.1041, -34.3281, -34.2597,\n",
      "        -34.2649, -34.2695, -34.2441, -34.2201, -34.2743, -34.2059, -34.2161,\n",
      "        -34.2505, -34.2161, -34.2206, -34.0410, -34.2127, -34.2098, -34.2600,\n",
      "        -34.1673, -34.1112, -34.1166, -34.1670, -34.1881, -34.2099, -34.2906],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(active.next_action(empty_board))\n",
    "print(active.get_Q(empty_board))\n",
    "print(torch.max(active.get_Q(empty_board), 0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "game = ConnectFourSimulator()\n",
    "val = input()\n",
    "while val != \"q\":\n",
    "    game_over, board, _, _, _, _ = game.take_action(int(val))\n",
    "    print(game_over)\n",
    "    print(board)\n",
    "    print(\"------------------------------------\")\n",
    "    if not game_over:\n",
    "        confirmation = \"r\"\n",
    "        while confirmation == \"r\":\n",
    "            pc_action = active.next_action(board)\n",
    "            print(pc_action)\n",
    "            confirmation = input()\n",
    "            if confirmation == \"c\":\n",
    "                game_over, board, _, _, _, _ = game.take_action(pc_action)\n",
    "                print(game_over)\n",
    "                print(board)\n",
    "    val = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = memory.sample(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_states = [ game for game in games if game[3] == 100 or game[3] == -100 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " [[-1.  1.  1. -1. -1.  1.  1.]\n",
      " [ 1. -1. -1. -1.  1. -1. -1.]\n",
      " [ 1.  0. -1.  1.  1.  0.  1.]\n",
      " [ 0.  0.  0.  1. -1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  1.  1. -1. -1.  1.  1.]\n",
      " [ 1. -1. -1. -1.  1. -1. -1.]\n",
      " [ 1.  0. -1.  1.  1. -1.  1.]\n",
      " [ 0.  0.  0.  1. -1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 19\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1. -1.  1. -1.  1.  1.]\n",
      " [ 1. -1. -1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1. -1.  1.  1. -1.]\n",
      " [-1.  1.  0.  0.  1.  0.  1.]\n",
      " [ 1.  0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]]\n",
      "After:\n",
      " [[-1. -1. -1.  1. -1.  1.  1.]\n",
      " [ 1. -1. -1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1. -1.  1.  1. -1.]\n",
      " [-1.  1.  0. -1.  1.  0.  1.]\n",
      " [ 1.  0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]]\n",
      "With action: 24\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 1. -1.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[ 1. -1.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: tensor(33, device='cuda:0')\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 1.  1. -1.  1. -1.  1. -1.]\n",
      " [ 1.  1. -1. -1. -1.  1. -1.]\n",
      " [ 1.  0. -1. -1. -1.  1.  1.]\n",
      " [-1.  0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  0.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.]]\n",
      "After:\n",
      " [[ 1.  1. -1.  1. -1.  1. -1.]\n",
      " [ 1.  1. -1. -1. -1.  1. -1.]\n",
      " [ 1.  0. -1. -1. -1.  1.  1.]\n",
      " [-1.  0.  1. -1.  1. -1. -1.]\n",
      " [ 0.  0.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.]]\n",
      "With action: 27\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 1. -1. -1.  1. -1. -1.  1.]\n",
      " [ 1.  1. -1.  1. -1.  1.  1.]\n",
      " [ 1. -1.  0. -1. -1. -1.  1.]\n",
      " [-1. -1.  0.  1.  0.  1. -1.]\n",
      " [ 1.  0.  0.  1.  0. -1.  1.]\n",
      " [ 0.  0.  0. -1.  0.  0.  1.]]\n",
      "After:\n",
      " [[ 1. -1. -1.  1. -1. -1.  1.]\n",
      " [ 1.  1. -1.  1. -1.  1.  1.]\n",
      " [ 1. -1.  0. -1. -1. -1.  1.]\n",
      " [-1. -1.  0.  1. -1.  1. -1.]\n",
      " [ 1.  0.  0.  1.  0. -1.  1.]\n",
      " [ 0.  0.  0. -1.  0.  0.  1.]]\n",
      "With action: 25\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1. -1. -1.  1.  1.  1.]\n",
      " [ 1.  1.  0.  1.  0.  0. -1.]\n",
      " [ 0. -1.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1. -1. -1.  1.  1.  1.]\n",
      " [ 1.  1.  0.  1.  0. -1. -1.]\n",
      " [ 0. -1.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: tensor(12, device='cuda:0')\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 1.  0.  1. -1. -1. -1.  1.]\n",
      " [ 1.  0.  1.  1. -1.  1. -1.]\n",
      " [ 0.  0. -1. -1. -1.  0.  1.]\n",
      " [ 0.  0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[ 1.  0.  1. -1. -1. -1.  1.]\n",
      " [ 1.  0.  1.  1. -1.  1. -1.]\n",
      " [-1.  0. -1. -1. -1.  0.  1.]\n",
      " [ 0.  0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: tensor(14, device='cuda:0')\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 1. -1.  1. -1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  0.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[ 1. -1.  1. -1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  0.  0.]\n",
      " [ 1.  0.  1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: tensor(16, device='cuda:0')\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  1.  1. -1.  1.  1.  0.]\n",
      " [ 1. -1. -1. -1. -1.  1.  0.]\n",
      " [-1.  1. -1.  1. -1. -1.  0.]\n",
      " [-1.  1.  1.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  1.  1. -1.  1.  1.  0.]\n",
      " [ 1. -1. -1. -1. -1.  1.  0.]\n",
      " [-1.  1. -1.  1. -1. -1.  0.]\n",
      " [-1.  1.  1.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 33\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  1.  1. -1.  1.  1. -1.]\n",
      " [ 1. -1. -1.  1. -1.  1.  1.]\n",
      " [-1.  1. -1.  1. -1.  1.  0.]\n",
      " [ 0. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  1.  1. -1.  1.  1. -1.]\n",
      " [ 1. -1. -1.  1. -1.  1.  1.]\n",
      " [-1.  1. -1.  1. -1.  1.  0.]\n",
      " [ 0. -1.  0. -1. -1. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 25\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 1. -1.  1.  1. -1.  1.  1.]\n",
      " [-1.  1. -1.  1. -1. -1. -1.]\n",
      " [ 1.  1. -1. -1. -1. -1. -1.]\n",
      " [-1. -1.  0.  1.  1.  1. -1.]\n",
      " [ 1.  1.  0.  1. -1. -1.  1.]\n",
      " [ 0.  1.  0.  1.  1. -1.  0.]]\n",
      "After:\n",
      " [[ 1. -1.  1.  1. -1.  1.  1.]\n",
      " [-1.  1. -1.  1. -1. -1. -1.]\n",
      " [ 1.  1. -1. -1. -1. -1. -1.]\n",
      " [-1. -1.  0.  1.  1.  1. -1.]\n",
      " [ 1.  1.  0.  1. -1. -1.  1.]\n",
      " [ 0.  1.  0.  1.  1. -1. -1.]]\n",
      "With action: 41\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in terminal_states:\n",
    "    print(\"Before:\\n\", state[0])\n",
    "    print(\"After:\\n\", state[1])\n",
    "    print(\"With action:\", state[2])\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "After:\n",
      " [[0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "With action: 3\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 18\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[ 0.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 4\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 32\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 8\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 34\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 38\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 10\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 13\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 0\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 10\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 14\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 18\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 26\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 18\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 13\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 37\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 41\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 27\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 29\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 36\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 28\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 40\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 22\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 25\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 27\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1.  0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 5\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 4\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 30\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 7\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 26\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 12\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 19\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 22\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 26\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 0\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 14\n",
      "Reward: 0\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 0\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 3\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 0\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 5\n",
      "Reward: -2\n",
      "---------------------------------------\n",
      "Before:\n",
      " [[-1. -1.  0.  1.  1.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "After:\n",
      " [[-1. -1.  0.  1.  1.  1.  1.]\n",
      " [ 1. -1.  0. -1.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "With action: 6\n",
      "Reward: 0\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in memory.memory[:42]:\n",
    "    print(\"Before:\\n\", state[0])\n",
    "    print(\"After:\\n\", state[1])\n",
    "    print(\"With action:\", state[2])\n",
    "    print(\"Reward:\", state[3])\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
