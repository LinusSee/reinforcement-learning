{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        #self.fc1.weight.data.fill_(0.0)\n",
    "        #self.fc1.bias.data.fill_(0.0)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        #self.fc2.weight.data.fill_(0.0)\n",
    "        #self.fc2.bias.data.fill_(0.0)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "        #self.fc3.weight.data.fill_(0.0)\n",
    "        #self.fc3.bias.data.fill_(0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(model, optimizer, x, y):\n",
    "    y_guess = model(x)\n",
    "    #print(\"Y:\", y)\n",
    "    #print(\"Y guess:\", y_guess)\n",
    "    y_guess = y_guess.clone()#.detach().requires_grad_()\n",
    "    loss = F.smooth_l1_loss(y_guess, y)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x1 = torch.tensor(np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 0]\n",
    "]).flatten()).float().requires_grad_()\n",
    "y1 = torch.tensor(0).float()\n",
    "\n",
    "x2 = torch.tensor(np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "]).flatten()).float().requires_grad_()\n",
    "y2 = torch.tensor(1).float()\n",
    "\n",
    "x3 = torch.tensor(np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, -1, -1],\n",
    "    [-1, -1, -1]\n",
    "]).flatten()).float().requires_grad_()\n",
    "y3 = torch.tensor(-1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1.]], grad_fn=<CatBackward>)\n",
      "tensor([[ 0.],\n",
      "        [ 1.],\n",
      "        [-1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x1)\n",
    "all_xs = torch.cat([x1.unsqueeze(0), x2.unsqueeze(0), x3.unsqueeze(0)])\n",
    "print(all_xs)\n",
    "#all_xs = torch.tensor(all_xs)\n",
    "#all_xs = torch.tensor([x1, x2, x3])\n",
    "all_ys = torch.tensor([y1, y2, y3]).unsqueeze(1)\n",
    "print(all_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import time\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1645], grad_fn=<AddBackward0>)\n",
      "tensor([0.1817], grad_fn=<AddBackward0>)\n",
      "tensor([0.1486], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(x1))\n",
    "print(model(x2))\n",
    "print(model(x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\linus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millisec: 40823\n",
      "Sec: 40.823\n"
     ]
    }
   ],
   "source": [
    "start = int(round(time.time() * 1000))\n",
    "\n",
    "for i in range(20_000):\n",
    "    optimize(model, optimizer, x1, y1)\n",
    "    optimize(model, optimizer, x2, y2)\n",
    "    optimize(model, optimizer, x3, y3)\n",
    "    #optimize(model, optimizer, all_xs, all_ys)\n",
    "\n",
    "end = int(round(time.time() * 1000))\n",
    "print(\"Millisec:\", end - start)\n",
    "print(\"Sec:\", (end - start) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching all at once 13.359 / 13.731 sec\n",
    "# Batching one after another 40.618 / 40.823 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], grad_fn=<AddBackward0>)\n",
      "tensor([1.], grad_fn=<AddBackward0>)\n",
      "tensor([-1.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(x1))\n",
    "print(model(x2))\n",
    "print(model(x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [ 1.],\n",
      "        [-1.]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model(all_xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
